{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mutual_information.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJbYT9K+Q0bBeTZYvIxd9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VRehnberg/mutual-information/blob/main/mutual_information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABjQs-_zOBIi",
        "outputId": "9b039e8e-b9c6-45e5-da24-612543edba5f"
      },
      "source": [
        "%%bash\n",
        "pip install git+https://github.com/VRehnberg/torch-utils.git"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/VRehnberg/torch-utils.git\n",
            "  Cloning https://github.com/VRehnberg/torch-utils.git to /tmp/pip-req-build-6hy6n1it\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied (use --upgrade to upgrade): torch-utils==0.0.1 from git+https://github.com/VRehnberg/torch-utils.git in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: torch-utils\n",
            "  Building wheel for torch-utils (PEP 517): started\n",
            "  Building wheel for torch-utils (PEP 517): finished with status 'done'\n",
            "  Created wheel for torch-utils: filename=torch_utils-0.0.1-cp37-none-any.whl size=5808 sha256=8def2f286943b2280c3383b628f09d38dbb4732334f369457d728eded0e3c231\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mcpxp9f1/wheels/69/5c/fd/8fe71800b6c3026c5683efb40102541c2e0d5a44121b15e6fa\n",
            "Successfully built torch-utils\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/VRehnberg/torch-utils.git /tmp/pip-req-build-6hy6n1it\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGuScJ-yt2z9"
      },
      "source": [
        "import torch\n",
        "from torch import nn, linalg\n",
        "from torch.autograd.functional import jacobian\n",
        "\n",
        "from torchutils.kmeans import kmeans"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Wphq9FsMwx"
      },
      "source": [
        "# Mutual Information\n",
        "This notebook was written to investigate a few different ways to estimate the mutual information between random variables from sampled data. This is then compared with the true mutual information.\n",
        "\n",
        "1. Analytical mutual information TODO\n",
        "2. Jacobian/Hessian based mutual information TODO\n",
        "3. Quantized/binned mutual information TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McncszxCma_A"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jfqX6vS8MD_"
      },
      "source": [
        "class NormalLinear(nn.Linear):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super().__init__(input_shape, output_shape)\n",
        "        self.input_shape = input_shape\n",
        "    \n",
        "    def output_mutual_information(self, partition):\n",
        "        '''\n",
        "            partition (BoolTensor): n_modules Ã— output_shape\n",
        "        '''\n",
        "        if (partition.int().sum(0) > 1).any():\n",
        "            raise NotImplementedError(\"MI for overlapping modules not implemented.\")\n",
        "\n",
        "        weight, bias = self.parameters()\n",
        "        #mean = bias\n",
        "        cov_full = weight @ weight.T\n",
        "\n",
        "        # Check ranks (this is unescessary if full rank)\n",
        "        rank0 = linalg.matrix_rank(cov_full)\n",
        "        rank1 = torch.sum(torch.hstack([\n",
        "            linalg.matrix_rank(cov_full[mask, :][:,mask]) for mask in partition\n",
        "        ]))\n",
        "        if rank0 < rank1:\n",
        "            return float(\"inf\")\n",
        "        elif rank1 != cov_full.size(0):\n",
        "            raise NotImplementedError()\n",
        "        \n",
        "        # Compute MI\n",
        "        det0 = cov_full.det()\n",
        "        det1 = torch.prod(torch.hstack([\n",
        "            cov_full[mask, :][:,mask].det() for mask in partition\n",
        "        ]))\n",
        "        return -0.5 * torch.log(det0 / det1)\n",
        "        \n",
        "    def sample(self, batch_shape):\n",
        "        return torch.randn(batch_shape, self.input_shape)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAVLB0eUCEb6",
        "outputId": "cce97ee8-a87a-45ef-c162-1db5365734dc"
      },
      "source": [
        "n_modules = 2\n",
        "in_size, out_size = (15, 7)\n",
        "nl = NormalLinear(in_size, out_size)\n",
        "partition = nn.functional.one_hot(torch.randint(n_modules, (out_size,))).bool().T\n",
        "with torch.no_grad():\n",
        "    print(nl.output_mutual_information(partition))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4771)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-8oqEATxuEH"
      },
      "source": [
        "## Network utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3PrzrHWxfbh"
      },
      "source": [
        "def get_activations(network, x):\n",
        "    activations = []\n",
        "    hooks = []\n",
        "    for name, m in network.named_modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            save_activations = lambda mod, inp, out: activations.append(out)\n",
        "            hooks.append(m.register_forward_hook(save_activations))\n",
        "    \n",
        "    network(x)\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    \n",
        "    return torch.hstack(activations)\n",
        "\n",
        "\n",
        "def batched_jacobian(func, x, to_embedding=False, **kwargs):\n",
        "\n",
        "    # Copmute batched Jacobian\n",
        "    new_func = lambda x: func(x).sum(0)\n",
        "    jac = jacobian(new_func, x, **kwargs)\n",
        "    \n",
        "    # Move batch dimension first\n",
        "    dims = torch.arange(jac.ndim, device=device)\n",
        "    batch_dim = dims[-x.ndim]\n",
        "    jac.movedims(dims[:batch_dim + 1], [batch_dim, *dims[:batch_dim]])\n",
        "\n",
        "    return jac\n",
        "\n",
        "\n",
        "def clean_mem():\n",
        "    gc.collect()\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzLolCqexxsU"
      },
      "source": [
        "## Mutual information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbDQJO7HoDCd"
      },
      "source": [
        "def jacobian_mutual_information(jac_full, jac_blocks):\n",
        "    assert jac_full.ndim == 3\n",
        "\n",
        "    # Covariences\n",
        "    def det(jac):\n",
        "        return jac.bmm(jac.transpose(1, 2)).det()\n",
        "\n",
        "    det_full = det(jac_full)\n",
        "    det_blocks = torch.stack([det(jac_block) for jac_block in jac_blocks], 1)\n",
        "\n",
        "    # Local mutual information\n",
        "    jmi = -0.5 * torch.log(det_full / torch.prod(det_blocks, 1))\n",
        "\n",
        "    return jmi.mean(0)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyjcdxJWA6w2",
        "outputId": "54478b3c-83d6-4947-ef61-c0087b3eab88"
      },
      "source": [
        "jac_full = torch.rand(7, 10, 30)\n",
        "partition = torch.randint(3, (10,))\n",
        "jac_blocks = [jac_full[:, id==partition, :] for id in torch.unique(partition)]\n",
        "jacobian_mutual_information(jac_full, jac_blocks)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6649)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC-Yoc1ueRcJ",
        "outputId": "d5169f2f-78aa-465b-afda-c12dac95b78a"
      },
      "source": [
        "help(kmeans)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function kmeans in module torchutils.kmeans:\n",
            "\n",
            "kmeans(points, k, global_start=1, max_iter=None, reinitialize_empty_clusters=True, verbose=False)\n",
            "    Naive K-means with parallelized global start.\n",
            "    \n",
            "    Arguments:\n",
            "        points (Tensor): Number of points times number of features.\n",
            "        k (int): Number of clusters.\n",
            "        global_start (int): Different intializations that are run in parallel.\n",
            "            Default 1.\n",
            "        reinatialize_empty_clusters (bool): If empty clusters are reinitialized.\n",
            "            Default True.\n",
            "        verbose (bool): Controls verbosity. Default True. \n",
            "    \n",
            "    Returns:\n",
            "        i_cluster (LongTensor): What cluster each point belongs to.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH0T7-pdyW5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649d6870-da71-4a78-f65d-31514c843e77"
      },
      "source": [
        "def quantized_mutual_information(activations, partition, n_bins, cluster_method=\"kmeans\"):\n",
        "    if not isinstance(partition, torch.BoolTensor):\n",
        "        raise TypeError(\"Datatype of partition should be BoolTensor.\")\n",
        "    device = activations.device\n",
        "    batch_size, n_features = activations.shape\n",
        "    n_parts = partition.size(0)\n",
        "    assert n_features == partition.size(1)\n",
        "    assert batch_size >= n_bins\n",
        "\n",
        "    if cluster_method==\"kmeans\":\n",
        "        def quantize(points):\n",
        "            # Cosine similarity\n",
        "            points = (points - points.mean(0, keepdim=True)) / points.std(0, keepdim=True)\n",
        "            return kmeans(points, n_bins ** n_parts).argsort(0)\n",
        "    else:\n",
        "        raise ValueError()\n",
        "\n",
        "    quantized_activations = torch.zeros((batch_size, n_parts), dtype=int, device=device)\n",
        "    for i_part, mask in enumerate(partition):\n",
        "        quantized_activations[:, i_part] = quantize(activations[:, mask])\n",
        "\n",
        "    # Compute pmfs\n",
        "    activations_onehot = nn.functional.one_hot(quantized_activations).float()\n",
        "    p_xy = torch.einsum(\"bij, bkl -> ikjl\", activations_onehot, activations_onehot) / batch_size\n",
        "\n",
        "    # Compute pairwise mutual information\n",
        "    p_x = torch.einsum(\"iikk -> ik\", p_xy)\n",
        "    qmin = p_xy.div(p_x.unsqueeze(0).unsqueeze(2)).div(p_x.unsqueeze(1).unsqueeze(3)).pow(p_xy).log().sum((2, 3))\n",
        "    return qmin\n",
        "    \n",
        "\n",
        "n_modules = 2\n",
        "in_size, out_size = (15, 7)\n",
        "activations = torch.rand(2000, out_size)\n",
        "partition = nn.functional.one_hot(torch.randint(n_modules, (out_size,))).bool().T\n",
        "with torch.no_grad():\n",
        "    print(quantized_mutual_information(activations, partition, 10))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 920,  606],\n",
            "        [1949, 1064],\n",
            "        [1722, 1547],\n",
            "        ...,\n",
            "        [ 273,  825],\n",
            "        [  18,  648],\n",
            "        [ 197, 1965]])\n",
            "tensor([[7.6008, 7.6008],\n",
            "        [7.6008, 7.6008]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFTZrQIf0XyD"
      },
      "source": [
        "\n",
        "    # v-- old below\n",
        "\n",
        "    ## Quantize activations\n",
        "    #batch_size, n_activations = activations.shape\n",
        "    #assert n_activations == partition.numel()\n",
        "    #assert batch_size >= n_bins\n",
        "    #quantized_activations = n_bins * activations.argsort(0).argsort(0) // batch_size\n",
        "\n",
        "    ## Compute pmfs\n",
        "    #activations_onehot = nn.functional.one_hot(quantized_activations).float()\n",
        "    #p_xy = torch.einsum(\"bij, bkl -> ikjl\", activations_onehot, activations_onehot) / batch_size\n",
        "\n",
        "    ## Compute pairwise mutual information\n",
        "    #p_x = torch.einsum(\"iikk -> ik\", p_xy)\n",
        "    #qmin = p_xy.div(p_x.unsqueeze(0).unsqueeze(2)).div(p_x.unsqueeze(1).unsqueeze(3)).pow(p_xy).log().sum((2, 3))\n",
        "    #return qmin\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}